{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77428142-6e49-4182-984b-51f223eb7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U sentence-transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3bd899-6f72-4198-9778-7502464b67e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from content_tree import *\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5f563ab-f9e3-472a-870f-50fd40ae26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    tree = ContentTree()\n",
    "    \n",
    "    # Build the textbook tree from markdown files\n",
    "    md_directory = \"/Users/chemxai/GenAI/AI_Tutor/mcp_kb/md_files\"\n",
    "    tree.build_textbook_tree(md_directory)\n",
    "    \n",
    "    # Print tree structure\n",
    "    print(\"Textbook Structure:\")\n",
    "    tree.print_tree_structure()\n",
    "    \n",
    "    # Get all nodes\n",
    "    all_nodes = tree.tree_node_iterator()\n",
    "    print(f\"\\nTotal nodes: {len(all_nodes)}\")\n",
    "    \n",
    "    # Find a specific chapter\n",
    "    chapter1 = tree.find_node_by_header(\"Chapter 1 - Essential Ideas\")\n",
    "    if chapter1:\n",
    "        print(f\"\\nFound: {chapter1}\")\n",
    "        print(f\"Content preview: {chapter1.content_text[:200]}...\")\n",
    "    \n",
    "    # Get content from a node and its children\n",
    "    if chapter1:\n",
    "        section_content = tree.content_retriever(chapter1)\n",
    "        print(f\"\\nChapter 1 total content length: {len(section_content)} characters\")\n",
    "    \n",
    "    # Test: Print headers of all child nodes to verify order\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ORDER VERIFICATION: All Root Child Nodes\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total root children: {len(tree.root.child_nodes)}\")\n",
    "    print(\"\\nOrder of all child nodes:\")\n",
    "    for i, child in enumerate(tree.root.child_nodes, 1):\n",
    "        print(f\"{i:2d}. [{child.node_id:4d}] Level {child.header_level}: {child.header}\")\n",
    "    \n",
    "    # Verify expected order\n",
    "    expected_order = [\"Preface\"] + [f\"Chapter {i} -\" for i in range(1, 22)] + [f\"Appendix {chr(65+i)}\" for i in range(13)]\n",
    "    print(f\"\\nExpected count: Preface(1) + Chapters(21) + Appendices(13) = 35 total\")\n",
    "    print(f\"Actual count: {len(tree.root.child_nodes)}\")\n",
    "    \n",
    "    # Check if order matches expected pattern\n",
    "    order_correct = True\n",
    "    for i, child in enumerate(tree.root.child_nodes):\n",
    "        if i == 0 and not child.header.startswith(\"Preface\"):\n",
    "            order_correct = False\n",
    "            print(f\"❌ Position {i+1}: Expected Preface, got '{child.header}'\")\n",
    "        elif 1 <= i <= 21 and not child.header.startswith(f\"Chapter {i}\"):\n",
    "            order_correct = False\n",
    "            print(f\"❌ Position {i+1}: Expected Chapter {i}, got '{child.header}'\")\n",
    "        elif i > 21 and not child.header.startswith(f\"Appendix {chr(65+i-22)}\"):\n",
    "            order_correct = False\n",
    "            print(f\"❌ Position {i+1}: Expected Appendix {chr(65+i-22)}, got '{child.header}'\")\n",
    "    \n",
    "    if order_correct:\n",
    "        print(\"✅ Order verification: All nodes are in correct order!\")\n",
    "    else:\n",
    "        print(\"❌ Order verification: Some nodes are out of order.\")\n",
    "\n",
    "def test1():\n",
    "    # Create a ContentTree instance\n",
    "    tree = ContentTree()\n",
    "\n",
    "    # Build the textbook tree from markdown files\n",
    "    md_directory = \"/Users/chemxai/GenAI/AI_Tutor/mcp_kb/md_files\"\n",
    "    tree.build_textbook_tree(md_directory)\n",
    "\n",
    "    # Rename repeating headers to make them unique\n",
    "    tree.rename_repeating_headers()\n",
    "\n",
    "    # Print tree structure\n",
    "    print(\"Textbook Structure:\")\n",
    "    tree.print_tree_structure()\n",
    "\n",
    "    # Generate summaries and keywords for all nodes\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENERATING SUMMARIES AND KEYWORDS\")\n",
    "    print(\"=\"*60)\n",
    "    #tree.generate_all_summaries_and_keywords()\n",
    "    tree.process_all_content()\n",
    "\n",
    "    # Print tree structure with summaries and keywords\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TREE STRUCTURE WITH SUMMARIES AND KEYWORDS\")\n",
    "    print(\"=\"*60)\n",
    "    tree.print_tree_structure(show_summary=True, show_keywords=True)\n",
    "\n",
    "    # Get all nodes\n",
    "    all_nodes = tree.tree_node_iterator()\n",
    "    print(f\"\\nTotal nodes: {len(all_nodes)}\")\n",
    "\n",
    "    # Find a specific chapter and show its enhanced information\n",
    "    chapter1 = tree.find_node_by_header(\"Chapter 1 - Essential Ideas\")\n",
    "    if chapter1:\n",
    "        print(f\"\\nFound: {chapter1}\")\n",
    "        print(f\"Content preview: {chapter1.content_text[:200]}...\")\n",
    "        print(f\"Summary: {chapter1.summary}\")\n",
    "        print(f\"Keywords: {', '.join(chapter1.keywords)}\")\n",
    "\n",
    "    # Get content from a node and its children\n",
    "    if chapter1:\n",
    "        section_content = tree.content_retriever(chapter1)\n",
    "        print(f\"\\nChapter 1 total content length: {len(section_content)} characters\")\n",
    "\n",
    "    # Test: Print headers of all child nodes to verify order\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ORDER VERIFICATION: All Root Child Nodes\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total root children: {len(tree.root.child_nodes)}\")\n",
    "    print(\"\\nOrder of all child nodes:\")\n",
    "    for i, child in enumerate(tree.root.child_nodes, 1):\n",
    "        print(f\"{i:2d}. [{child.node_id:4d}] Level {child.header_level}: {child.header}\")\n",
    "\n",
    "    # Verify expected order\n",
    "    expected_order = [\"Preface\"] + [f\"Chapter {i} -\" for i in range(1, 22)] + [f\"Appendix {chr(65+i)}\" for i in range(13)]\n",
    "    print(f\"\\nExpected count: Preface(1) + Chapters(21) + Appendices(13) = 35 total\")\n",
    "    print(f\"Actual count: {len(tree.root.child_nodes)}\")\n",
    "\n",
    "    # Check if order matches expected pattern\n",
    "    order_correct = True\n",
    "    for i, child in enumerate(tree.root.child_nodes):\n",
    "        if i == 0 and not child.header.startswith(\"Preface\"):\n",
    "            order_correct = False\n",
    "            print(f\"❌ Position {i+1}: Expected Preface, got '{child.header}'\")\n",
    "        elif 1 <= i <= 21 and not child.header.startswith(f\"Chapter {i}\"):\n",
    "            order_correct = False\n",
    "            print(f\"❌ Position {i+1}: Expected Chapter {i}, got '{child.header}'\")\n",
    "        elif i > 21 and not child.header.startswith(f\"Appendix {chr(65+i-22)}\"):\n",
    "            order_correct = False\n",
    "            print(f\"❌ Position {i+1}: Expected Appendix {chr(65+i-22)}, got '{child.header}'\")\n",
    "\n",
    "    if order_correct:\n",
    "        print(\"✅ Order verification: All nodes are in correct order!\")\n",
    "    else:\n",
    "        print(\"❌ Order verification: Some nodes are out of order.\")\n",
    "\n",
    "    # Show some examples of generated summaries and keywords\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXAMPLES OF GENERATED SUMMARIES AND KEYWORDS\")\n",
    "    print(\"=\"*60)\n",
    "    content_nodes = [node for node in all_nodes if node.header_level > 0 and node.content_text.strip()]\n",
    "    for i, node in enumerate(content_nodes[:5]):  # Show first 5 content nodes\n",
    "        print(f\"\\nNode {i+1}: {node.header}\")\n",
    "        print(f\"Content length: {len(node.content_text)} characters\")\n",
    "        print(f\"Summary: {node.summary}\")\n",
    "        print(f\"Keywords: {', '.join(node.keywords)}\")\n",
    "        print(\"-\" * 40)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf13e37e-2618-40c4-b517-623ce91eca6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textbook Structure:\n",
      "[1] Level 0: Root (content: 0 chars)\n",
      "  [2] Level 2: Preface (content: 205 chars)\n",
      "    [3] Level 3: About OpenStax (content: 668 chars)\n",
      "      [4] Level 4: About OpenStax resources Customization (content: 944 chars)\n",
      "      [5] Level 4: Errata (content: 535 chars)\n",
      "      [6] Level 4: Format (content: 107 chars)\n",
      "    [7] Level 3: About Chemistry 2e (content: 744 chars)\n",
      "      [8] Level 4: Coverage and scope (content: 732 chars)\n",
      "      [9] Level 4: Changes to the second edition (content: 1681 chars)\n",
      "      [10] Level 4: Pedagogical foundation and features (content: 931 chars)\n",
      "      [11] Level 4: Comprehensive art program (content: 253 chars)\n",
      "      [12] Level 4: Interactives that engage (content: 226 chars)\n",
      "      [13] Level 4: Assessments that reinforce key concepts (content: 316 chars)\n",
      "    [14] Level 3: Additional resources (content: 0 chars)\n",
      "      [15] Level 4: Student and instructor resources (content: 367 chars)\n",
      "      [16] Level 4: Community Hubs (content: 757 chars)\n",
      "      [17] Level 4: Technology partners (content: 244 chars)\n",
      "    [18] Level 3: About the authors <br> Senior contributing authors (content: 0 chars)\n",
      "      [19] Level 4: Paul Flowers, University of North Carolina at Pembroke (content: 503 chars)\n",
      "      [20] Level 4: Klaus Theopold, University of Delaware (content: 682 chars)\n",
      "      [21] Level 4: Richard Langley, Stephen F. Austin State University (content: 649 chars)\n",
      "      [22] Level 4: William R. Robinson, PhD (content: 0 chars)\n",
      "      [23] Level 4: Contributing authors (content: 583 chars)\n",
      "      [24] Level 4: Reviewers (content: 2280 chars)\n",
      "  [25] Level 2: Chapter 1 - Essential Ideas (content: 1971 chars)\n",
      "    [26] Level 3: 1.1 Chemistry in Context (content: 2726 chars)\n",
      "      [27] Level 4: Chemistry: The Central Science (content: 2763 chars)\n",
      "      [28] Level 4: The Scientific Method (content: 1900 chars)\n",
      "      [29] Level 4: The Domains of Chemistry (content: 3742 chars)\n",
      "    [30] Level 3: 1.2 Phases and Classification of Matter (content: 5955 chars)\n",
      "      [31] Level 4: Classifying Matter (content: 6699 chars)\n",
      "      [32] Level 4: Atoms and Molecules (content: 5066 chars)\n",
      "      [33] Level 4: 1.2 Phases and Classification of Matter Chemistry in Everyday Life (content: 2214 chars)\n",
      "      [34] Level 4: 1.2 Phases and Classification of Matter Chemistry in Everyday Life (content: 1428 chars)\n",
      "    [35] Level 3: 1.3 Physical and Chemical Properties (content: 5010 chars)\n",
      "      [36] Level 4: 1.3 Physical and Chemical Properties Chemistry in Everyday Life (content: 4235 chars)\n",
      "    [37] Level 3: 1.4 Measurements (content: 5170 chars)\n",
      "      [38] Level 4: SI Base Units (content: 393 chars)\n",
      "      [39] Level 4: Length (content: 929 chars)\n",
      "      [40] Level 4: Mass (content: 761 chars)\n",
      "      [41] Level 4: Temperature (content: 920 chars)\n",
      "      [42] Level 4: Time (content: 314 chars)\n",
      "      [43] Level 4: Derived SI Units (content: 197 chars)\n",
      "      [44] Level 4: Volume (content: 1389 chars)\n",
      "      [45] Level 4: Density (content: 2471 chars)\n",
      "      [46] Level 4: Example 1.1 (content: 1776 chars)\n",
      "      [47] Level 4: Example 1.2 (content: 1731 chars)\n",
      "    [48] Level 3: 1.5 Measurement Uncertainty, Accuracy, and Precision (content: 925 chars)\n",
      "      [49] Level 4: Significant Figures in Measurement (content: 5523 chars)\n",
      "      [50] Level 4: Significant Figures in Calculations (content: 1935 chars)\n",
      "      [51] Level 4: Example 1.3 (content: 937 chars)\n",
      "      [52] Level 4: Example 1.4 (content: 756 chars)\n",
      "      [53] Level 4: Example 1.5 (content: 1440 chars)\n",
      "      [54] Level 4: Example 1.6 (content: 694 chars)\n",
      "      [55] Level 4: Example 1.7 (content: 1619 chars)\n",
      "      [56] Level 4: Accuracy and Precision (content: 2263 chars)\n",
      "    [57] Level 3: 1.6 Mathematical Treatment of Measurement Results (content: 2790 chars)\n",
      "      [58] Level 4: Conversion Factors and Dimensional Analysis (content: 2153 chars)\n",
      "      [59] Level 4: Example 1.8 (content: 928 chars)\n",
      "\n",
      "============================================================\n",
      "GENERATING SUMMARIES AND KEYWORDS\n",
      "============================================================\n",
      "Processing all content for 58 nodes...\n",
      "Processing node 1/58: Preface\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 2 texts in 1 batches...\n",
      "Processing node 2/58: About OpenStax\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 4 texts in 1 batches...\n",
      "Processing node 3/58: About OpenStax resources Customization\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 3 texts in 1 batches...\n",
      "Generating embeddings for 7 texts in 1 batches...\n",
      "Processing node 4/58: Errata\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 6 texts in 1 batches...\n",
      "Processing node 5/58: Format\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Processing node 6/58: About Chemistry 2e\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 5 texts in 1 batches...\n",
      "Processing node 7/58: Coverage and scope\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 2 texts in 1 batches...\n",
      "Generating embeddings for 5 texts in 1 batches...\n",
      "Processing node 8/58: Changes to the second edition\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 4 texts in 1 batches...\n",
      "Generating embeddings for 15 texts in 1 batches...\n",
      "Processing node 9/58: Pedagogical foundation and features\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 4 texts in 1 batches...\n",
      "Generating embeddings for 7 texts in 1 batches...\n",
      "Processing node 10/58: Comprehensive art program\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 4 texts in 1 batches...\n",
      "Generating embeddings for 4 texts in 1 batches...\n",
      "Processing node 11/58: Interactives that engage\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 2 texts in 1 batches...\n",
      "Generating embeddings for 2 texts in 1 batches...\n",
      "Processing node 12/58: Assessments that reinforce key concepts\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 2 texts in 1 batches...\n",
      "Skipping node 13/58 (no content): Additional resources\n",
      "Processing node 14/58: Student and instructor resources\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 3 texts in 1 batches...\n",
      "Processing node 15/58: Community Hubs\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 4 texts in 1 batches...\n",
      "Processing node 16/58: Technology partners\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 2 texts in 1 batches...\n",
      "Skipping node 17/58 (no content): About the authors <br> Senior contributing authors\n",
      "Processing node 18/58: Paul Flowers, University of North Carolina at Pembroke\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 3 texts in 1 batches...\n",
      "Processing node 19/58: Klaus Theopold, University of Delaware\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 5 texts in 1 batches...\n",
      "Processing node 20/58: Richard Langley, Stephen F. Austin State University\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 4 texts in 1 batches...\n",
      "Skipping node 21/58 (no content): William R. Robinson, PhD\n",
      "Processing node 22/58: Contributing authors\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Processing node 23/58: Reviewers\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 2 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Processing node 24/58: Chapter 1 - Essential Ideas\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 6 texts in 1 batches...\n",
      "Generating embeddings for 13 texts in 1 batches...\n",
      "Processing node 25/58: 1.1 Chemistry in Context\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 5 texts in 1 batches...\n",
      "Generating embeddings for 19 texts in 1 batches...\n",
      "Processing node 26/58: Chemistry: The Central Science\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 3 texts in 1 batches...\n",
      "Generating embeddings for 17 texts in 1 batches...\n",
      "Processing node 27/58: The Scientific Method\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 3 texts in 1 batches...\n",
      "Generating embeddings for 14 texts in 1 batches...\n",
      "Processing node 28/58: The Domains of Chemistry\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 7 texts in 1 batches...\n",
      "Generating embeddings for 27 texts in 1 batches...\n",
      "Processing node 29/58: 1.2 Phases and Classification of Matter\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 16 texts in 1 batches...\n",
      "Generating embeddings for 44 texts in 2 batches...\n",
      "Processing node 30/58: Classifying Matter\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 20 texts in 1 batches...\n",
      "Generating embeddings for 47 texts in 2 batches...\n",
      "Processing node 31/58: Atoms and Molecules\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 8 texts in 1 batches...\n",
      "Generating embeddings for 37 texts in 2 batches...\n",
      "Processing node 32/58: 1.2 Phases and Classification of Matter Chemistry in Everyday Life\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 6 texts in 1 batches...\n",
      "Generating embeddings for 19 texts in 1 batches...\n",
      "Processing node 33/58: 1.2 Phases and Classification of Matter Chemistry in Everyday Life\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 3 texts in 1 batches...\n",
      "Generating embeddings for 9 texts in 1 batches...\n",
      "Processing node 34/58: 1.3 Physical and Chemical Properties\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 9 texts in 1 batches...\n",
      "Generating embeddings for 34 texts in 2 batches...\n",
      "Processing node 35/58: 1.3 Physical and Chemical Properties Chemistry in Everyday Life\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 9 texts in 1 batches...\n",
      "Generating embeddings for 17 texts in 1 batches...\n",
      "Processing node 36/58: 1.4 Measurements\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 14 texts in 1 batches...\n",
      "Generating embeddings for 25 texts in 1 batches...\n",
      "Processing node 37/58: SI Base Units\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 4 texts in 1 batches...\n",
      "Processing node 38/58: Length\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 2 texts in 1 batches...\n",
      "Generating embeddings for 7 texts in 1 batches...\n",
      "Processing node 39/58: Mass\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 2 texts in 1 batches...\n",
      "Generating embeddings for 8 texts in 1 batches...\n",
      "Processing node 40/58: Temperature\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 2 texts in 1 batches...\n",
      "Generating embeddings for 7 texts in 1 batches...\n",
      "Processing node 41/58: Time\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 3 texts in 1 batches...\n",
      "Processing node 42/58: Derived SI Units\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 2 texts in 1 batches...\n",
      "Processing node 43/58: Volume\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 4 texts in 1 batches...\n",
      "Generating embeddings for 14 texts in 1 batches...\n",
      "Processing node 44/58: Density\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 7 texts in 1 batches...\n",
      "Generating embeddings for 11 texts in 1 batches...\n",
      "Processing node 45/58: Example 1.1\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 11 texts in 1 batches...\n",
      "Generating embeddings for 10 texts in 1 batches...\n",
      "Processing node 46/58: Example 1.2\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 12 texts in 1 batches...\n",
      "Generating embeddings for 11 texts in 1 batches...\n",
      "Processing node 47/58: 1.5 Measurement Uncertainty, Accuracy, and Precision\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 3 texts in 1 batches...\n",
      "Generating embeddings for 6 texts in 1 batches...\n",
      "Processing node 48/58: Significant Figures in Measurement\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 9 texts in 1 batches...\n",
      "Generating embeddings for 39 texts in 2 batches...\n",
      "Processing node 49/58: Significant Figures in Calculations\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 6 texts in 1 batches...\n",
      "Generating embeddings for 8 texts in 1 batches...\n",
      "Processing node 50/58: Example 1.3\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 7 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Processing node 51/58: Example 1.4\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 10 texts in 1 batches...\n",
      "Generating embeddings for 7 texts in 1 batches...\n",
      "Processing node 52/58: Example 1.5\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 14 texts in 1 batches...\n",
      "Generating embeddings for 6 texts in 1 batches...\n",
      "Processing node 53/58: Example 1.6\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 6 texts in 1 batches...\n",
      "Generating embeddings for 4 texts in 1 batches...\n",
      "Processing node 54/58: Example 1.7\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 15 texts in 1 batches...\n",
      "Generating embeddings for 10 texts in 1 batches...\n",
      "Processing node 55/58: Accuracy and Precision\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 6 texts in 1 batches...\n",
      "Generating embeddings for 13 texts in 1 batches...\n",
      "Processing node 56/58: 1.6 Mathematical Treatment of Measurement Results\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 12 texts in 1 batches...\n",
      "Generating embeddings for 10 texts in 1 batches...\n",
      "Processing node 57/58: Conversion Factors and Dimensional Analysis\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 8 texts in 1 batches...\n",
      "Generating embeddings for 16 texts in 1 batches...\n",
      "Processing node 58/58: Example 1.8\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 1 texts in 1 batches...\n",
      "Generating embeddings for 9 texts in 1 batches...\n",
      "Generating embeddings for 5 texts in 1 batches...\n",
      "Complete content processing finished!\n",
      "\n",
      "============================================================\n",
      "TREE STRUCTURE WITH SUMMARIES AND KEYWORDS\n",
      "============================================================\n",
      "[1] Level 0: Root (content: 0 chars)\n",
      "  [2] Level 2: Preface (content: 205 chars | Summary: \"Chemistry 2e, an OpenStax resource, offers high-q... | Keywords: Chemistry, OpenStax, textbook, student, access)\n",
      "    [3] Level 3: About OpenStax (content: 668 chars | Summary: OpenStax, a Rice University nonprofit, aims to enh... | Keywords: OpenStax, nonprofit, Rice, University, student)\n",
      "      [4] Level 4: About OpenStax resources Customization (content: 944 chars | Summary: Chemistry 2e is licensed under CC BY, allowing dis... | Keywords: Chemistry, Creative, Commons, Attribution, OpenStax)\n",
      "      [5] Level 4: Errata (content: 535 chars | Summary: OpenStax textbooks are rigorously reviewed but may... | Keywords: OpenStax, textbooks, review, process, errors)\n",
      "      [6] Level 4: Format (content: 107 chars | Summary: Access the textbook for free online or as a PDF vi... | Keywords: textbook, free, web, view, PDF)\n",
      "    [7] Level 3: About Chemistry 2e (content: 744 chars | Summary: Chemistry 2e is a textbook for a two-semester gene... | Keywords: Chemistry, general, chemistry, core, concepts)\n",
      "      [8] Level 4: Coverage and scope (content: 732 chars | Summary: Our Chemistry 2e textbook follows a nationwide sco... | Keywords: Chemistry, textbook, general, chemistry, scope)\n",
      "      [9] Level 4: Changes to the second edition (content: 1681 chars | Summary: OpenStax's Chemistry 2e includes extensive content... | Keywords: OpenStax, second, edition, Chemistry, user)\n",
      "      [10] Level 4: Pedagogical foundation and features (content: 931 chars | Summary: Chemistry 2e features engage students with scienti... | Keywords: Chemistry, scientific, inquiry, students, educators)\n",
      "      [11] Level 4: Comprehensive art program (content: 253 chars | Summary: Our art program uses clear illustrations, diagrams... | Keywords: art, program, students, understanding, concepts)\n",
      "      [12] Level 4: Interactives that engage (content: 226 chars | Summary: Chemistry $2 e$ enhances learning with interactive... | Keywords: Chemistry, interactive, exercises, animations, Link)\n",
      "      [13] Level 4: Assessments that reinforce key concepts (content: 316 chars | Summary: In-chapter Examples guide students through problem... | Keywords: In, chapter, Examples, students, problems)\n",
      "    [14] Level 3: Additional resources (content: 0 chars)\n",
      "      [15] Level 4: Student and instructor resources (content: 367 chars | Summary: Additional resources for OpenStax books include Ge... | Keywords: resources, students, instructors, Getting, Started)\n",
      "      [16] Level 4: Community Hubs (content: 757 chars | Summary: OpenStax collaborates with ISKME to provide Commun... | Keywords: OpenStax, ISKME, Community, Hubs, OER)\n",
      "      [17] Level 4: Technology partners (content: 244 chars | Summary: Technology partners provide optional low-cost tool... | Keywords: allies, high, quality, learning, materials)\n",
      "    [18] Level 3: About the authors <br> Senior contributing authors (content: 0 chars)\n",
      "      [19] Level 4: Paul Flowers, University of North Carolina at Pembroke (content: 503 chars | Summary: Dr. Paul Flowers earned degrees in Chemistry, cond... | Keywords: Dr, Paul, Flowers, BS, in)\n",
      "      [20] Level 4: Klaus Theopold, University of Delaware (content: 682 chars | Summary: Dr. Klaus Theopold, born in Berlin, earned his Vor... | Keywords: Dr, Klaus, Theopold, Berlin, Germany)\n",
      "      [21] Level 4: Richard Langley, Stephen F. Austin State University (content: 649 chars | Summary: Dr. Richard Langley earned degrees in Chemistry an... | Keywords: Richard, Langley, BS, Chemistry, Mineralogy)\n",
      "      [22] Level 4: William R. Robinson, PhD (content: 0 chars)\n",
      "      [23] Level 4: Contributing authors (content: 583 chars | Summary: A list of 14 individuals from various educational ... | Keywords: Mark, Blaser, Shasta, College, Simon)\n",
      "      [24] Level 4: Reviewers (content: 2280 chars | Summary: The list includes names and affiliations of indivi... | Keywords: universities, colleges, educators, academic, institutions)\n",
      "  [25] Level 2: Chapter 1 - Essential Ideas (content: 1971 chars | Summary: Chemistry is integral to daily life, influencing a... | Keywords: chemistry, chemical, substances, processes, existence)\n",
      "    [26] Level 3: 1.1 Chemistry in Context (content: 2726 chars | Summary: This module explores the historical development of... | Keywords: chemistry, historical, development, scientific, method)\n",
      "      [27] Level 4: Chemistry: The Central Science (content: 2763 chars | Summary: Chemistry, known as the central science, connects ... | Keywords: chemistry, central, science, STEM, interdisciplinary)\n",
      "      [28] Level 4: The Scientific Method (content: 1900 chars | Summary: Chemistry is a science grounded in observation and... | Keywords: Chemistry, science, observation, experimentation, laws)\n",
      "      [29] Level 4: The Domains of Chemistry (content: 3742 chars | Summary: Chemists study matter and energy across three doma... | Keywords: chemists, matter, energy, domains, macroscopic)\n",
      "    [30] Level 3: 1.2 Phases and Classification of Matter (content: 5955 chars | Summary: This text explains the basic properties of matter ... | Keywords: matter, states, solid, liquid, gas)\n",
      "      [31] Level 4: Classifying Matter (content: 6699 chars | Summary: Matter is classified into mixtures and pure substa... | Keywords: matter, classification, mixtures, pure, substances)\n",
      "      [32] Level 4: Atoms and Molecules (content: 5066 chars | Summary: An atom is the smallest unit of an element with it... | Keywords: atom, element, chemical, combination, gold)\n",
      "      [33] Level 4: 1.2 Phases and Classification of Matter Chemistry in Everyday Life (content: 2214 chars | Summary: Water can be decomposed into hydrogen and oxygen g... | Keywords: water, hydrogen, oxygen, decomposition, battery)\n",
      "      [34] Level 4: 1.2 Phases and Classification of Matter Chemistry in Everyday Life (content: 1428 chars | Summary: Cell phones are complex devices made from a divers... | Keywords: cell, phones, chemical, substances, chemical)\n",
      "    [35] Level 3: 1.3 Physical and Chemical Properties (content: 5010 chars | Summary: This section explains how to distinguish physical ... | Keywords: properties, matter, physical, properties, chemical)\n",
      "      [36] Level 4: 1.3 Physical and Chemical Properties Chemistry in Everyday Life (content: 4235 chars | Summary: The NFPA 704 Hazard Identification System uses a d... | Keywords: hazard, diamond, NFPA, chemical, hazards)\n",
      "    [37] Level 3: 1.4 Measurements (content: 5170 chars | Summary: This section covers the basics of measurement, inc... | Keywords: measurement, quantity, properties, units, metric)\n",
      "      [38] Level 4: SI Base Units (content: 393 chars | Summary: The metric system, later the SI system, was establ... | Keywords: metric, system, SI, system, French)\n",
      "      [39] Level 4: Length (content: 929 chars | Summary: The meter is the standard unit of length in the SI... | Keywords: meter, SI, metric, system, length)\n",
      "      [40] Level 4: Mass (content: 761 chars | Summary: The kilogram is the SI unit of mass, originally de... | Keywords: kilogram, SI, system, mass, platinum)\n",
      "      [41] Level 4: Temperature (content: 920 chars | Summary: Temperature is an intensive property, with the SI ... | Keywords: temperature, intensive, property, SI, unit)\n",
      "      [42] Level 4: Time (content: 314 chars | Summary: The SI base unit of time is the second (s), with p... | Keywords: SI, base, unit, time, second)\n",
      "      [43] Level 4: Derived SI Units (content: 197 chars | Summary: SI base units allow deriving other units, such as ... | Keywords: SI, base, units, length, volume)\n",
      "      [44] Level 4: Volume (content: 1389 chars | Summary: Volume measures space occupied by an object, with ... | Keywords: volume, space, SI, unit, cubic)\n",
      "      [45] Level 4: Density (content: 2471 chars | Summary: Density is calculated as mass divided by volume, w... | Keywords: density, mass, volume, substance, SI)\n",
      "      [46] Level 4: Example 1.1 (content: 1776 chars | Summary: The text explains how to calculate density using m... | Keywords: density, gold, lead, mass, volume)\n",
      "      [47] Level 4: Example 1.2 (content: 1731 chars | Summary: The text explains how to determine the density of ... | Keywords: density, displacement, water, red, block)\n",
      "    [48] Level 3: 1.5 Measurement Uncertainty, Accuracy, and Precision (content: 925 chars | Summary: This section explains accuracy, precision, exact v... | Keywords: accuracy, precision, exact, numbers, uncertain)\n",
      "      [49] Level 4: Significant Figures in Measurement (content: 5523 chars | Summary: Measurements are inherently uncertain, especially ... | Keywords: measurements, volume, graduated, cylinder, meniscus)\n",
      "      [50] Level 4: Significant Figures in Calculations (content: 1935 chars | Summary: Uncertainty in calculations stems from measurement... | Keywords: uncertainty, measurement, significant, figures, rounding)\n",
      "      [51] Level 4: Example 1.3 (content: 937 chars | Summary: The text explains rounding numbers to significant ... | Keywords: rounding, numbers, significant, figures, solution)\n",
      "      [52] Level 4: Example 1.4 (content: 756 chars | Summary: When adding or subtracting numbers, round the resu... | Keywords: significant, figures, addition, subtraction, rounding)\n",
      "      [53] Level 4: Example 1.5 (content: 1440 chars | Summary: When multiplying or dividing, round the result to ... | Keywords: multiplication, division, significant, figures, rounding)\n",
      "      [54] Level 4: Example 1.6 (content: 694 chars | Summary: The text explains how to calculate the volume of a... | Keywords: significant, figures, volume, calculation, rectangular)\n",
      "      [55] Level 4: Example 1.7 (content: 1619 chars | Summary: The experiment determines the density of rebar usi... | Keywords: density, water, displacement, rebar, iron)\n",
      "      [56] Level 4: Accuracy and Precision (content: 2263 chars | Summary: Scientists assess measurement quality by evaluatin... | Keywords: scientists, measurements, precision, accuracy, results)\n",
      "    [57] Level 3: 1.6 Mathematical Treatment of Measurement Results (content: 2790 chars | Summary: Dimensional analysis, or the factor-label method, ... | Keywords: dimensional, analysis, factor, label, unit)\n",
      "      [58] Level 4: Conversion Factors and Dimensional Analysis (content: 2153 chars | Summary: Unit conversion factors are ratios of equivalent q... | Keywords: unit, conversion, factor, equivalent, quantities)\n",
      "      [59] Level 4: Example 1.8 (content: 928 chars | Summary: The text explains how to convert the mass of a com... | Keywords: unit, conversion, factor, mass, competition)\n",
      "\n",
      "Total nodes: 59\n",
      "\n",
      "Found: ContentNode(id=25, level=2, header='Chapter 1 - Essential Ideas', children=6)\n",
      "Content preview: ![Image](Chapter_1_images/img-0.jpeg)\n",
      "\n",
      "Figure 1.1 Chemical substances and processes are essential for our existence, providing sustenance, keeping us clean and healthy, fabricating electronic devices,...\n",
      "Summary: Chemistry is integral to daily life, influencing activities like making coffee, cooking, using electronics, and driving. This course explores essential principles of modern chemistry.\n",
      "Keywords: chemistry, chemical, substances, processes, existence, sustenance, health, electronics, transportation\n",
      "\n",
      "Chapter 1 total content length: 82832 characters\n",
      "\n",
      "============================================================\n",
      "ORDER VERIFICATION: All Root Child Nodes\n",
      "============================================================\n",
      "Total root children: 2\n",
      "\n",
      "Order of all child nodes:\n",
      " 1. [   2] Level 2: Preface\n",
      " 2. [  25] Level 2: Chapter 1 - Essential Ideas\n",
      "\n",
      "Expected count: Preface(1) + Chapters(21) + Appendices(13) = 35 total\n",
      "Actual count: 2\n",
      "✅ Order verification: All nodes are in correct order!\n",
      "\n",
      "============================================================\n",
      "EXAMPLES OF GENERATED SUMMARIES AND KEYWORDS\n",
      "============================================================\n",
      "\n",
      "Node 1: Preface\n",
      "Content length: 205 characters\n",
      "Summary: \"Chemistry 2e, an OpenStax resource, offers high-quality, rigorously academic learning materials at minimal cost to enhance student access.\"\n",
      "Keywords: Chemistry, OpenStax, textbook, student, access, high, quality, learning, materials\n",
      "----------------------------------------\n",
      "\n",
      "Node 2: About OpenStax\n",
      "Content length: 668 characters\n",
      "Summary: OpenStax, a Rice University nonprofit, aims to enhance education access by publishing open textbooks and offering personalized learning tools, supported by partnerships and alliances.\n",
      "Keywords: OpenStax, nonprofit, Rice, University, student, access, education, openly, licensed\n",
      "----------------------------------------\n",
      "\n",
      "Node 3: About OpenStax resources Customization\n",
      "Content length: 944 characters\n",
      "Summary: Chemistry 2e is licensed under CC BY, allowing distribution, remixing, and customization. Instructors can use full or selected sections, create custom versions, and provide direct links in syllabi.\n",
      "Keywords: Chemistry, Creative, Commons, Attribution, OpenStax, openly, licensed, remix, customized\n",
      "----------------------------------------\n",
      "\n",
      "Node 4: Errata\n",
      "Content length: 535 characters\n",
      "Summary: OpenStax textbooks are rigorously reviewed but may contain errors. Updates are made periodically when necessary, and users can submit corrections reviewed by experts. Past errata are transparently listed on book pages.\n",
      "Keywords: OpenStax, textbooks, review, process, errors, updates, pedagogically, necessary, correction\n",
      "----------------------------------------\n",
      "\n",
      "Node 5: Format\n",
      "Content length: 107 characters\n",
      "Summary: Access the textbook for free online or as a PDF via OpenStax.org, or purchase it in print at a low cost.\n",
      "Keywords: textbook, free, web, view, PDF, OpenStax, org, low, cost\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "content_tree = test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a66d8b-0f4f-4223-96b2-e583c72b04b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TESTING UNIFIED SEARCH FUNCTIONALITY\n",
      "================================================================================\n",
      "Building tree from: /Users/chemxai/GenAI/AI_Tutor/mcp_kb/md_files\n",
      "\n",
      "Processing content and creating search indexes...\n",
      "================================================================================\n",
      "COMPREHENSIVE CONTENT TREE PROCESSING\n",
      "================================================================================\n",
      "Processing 55 content nodes...\n",
      "LLM Model: qwen2.5vl:32b\n",
      "Embedding Model: text-embedding-3-large\n",
      "Generate Embeddings: False\n",
      "Create Inverse Index: True\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/55] Processing node 2: Preface\n",
      "Content length: 205 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 106 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 2 items\n",
      "\n",
      "[2/55] Processing node 3: About OpenStax\n",
      "Content length: 668 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 151 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 4 items\n",
      "\n",
      "[3/55] Processing node 4: About OpenStax resources Customization\n",
      "Content length: 944 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 204 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 3 items\n",
      "  ✓ Sentences: 7 items\n",
      "\n",
      "[4/55] Processing node 5: Errata\n",
      "Content length: 535 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 195 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 6 items\n",
      "\n",
      "[5/55] Processing node 6: Format\n",
      "Content length: 107 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 102 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 1 items\n",
      "\n",
      "[6/55] Processing node 7: About Chemistry 2e\n",
      "Content length: 744 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 191 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 5 items\n",
      "\n",
      "[7/55] Processing node 8: Coverage and scope\n",
      "Content length: 732 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 192 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 2 items\n",
      "  ✓ Sentences: 5 items\n",
      "\n",
      "[8/55] Processing node 9: Changes to the second edition\n",
      "Content length: 1681 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 171 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 4 items\n",
      "  ✓ Sentences: 15 items\n",
      "\n",
      "[9/55] Processing node 10: Pedagogical foundation and features\n",
      "Content length: 931 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 152 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 4 items\n",
      "  ✓ Sentences: 7 items\n",
      "\n",
      "[10/55] Processing node 11: Comprehensive art program\n",
      "Content length: 253 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 115 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 4 items\n",
      "  ✓ Sentences: 4 items\n",
      "\n",
      "[11/55] Processing node 12: Interactives that engage\n",
      "Content length: 226 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 151 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 2 items\n",
      "  ✓ Sentences: 2 items\n",
      "\n",
      "[12/55] Processing node 13: Assessments that reinforce key concepts\n",
      "Content length: 316 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 170 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 2 items\n",
      "\n",
      "[13/55] Processing node 15: Student and instructor resources\n",
      "Content length: 367 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 149 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 3 items\n",
      "\n",
      "[14/55] Processing node 16: Community Hubs\n",
      "Content length: 757 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 159 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 4 items\n",
      "\n",
      "[15/55] Processing node 17: Technology partners\n",
      "Content length: 244 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 131 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 2 items\n",
      "\n",
      "[16/55] Processing node 19: Paul Flowers, University of North Carolina at Pembroke\n",
      "Content length: 503 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 186 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 3 items\n",
      "\n",
      "[17/55] Processing node 20: Klaus Theopold, University of Delaware\n",
      "Content length: 682 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 192 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 5 items\n",
      "\n",
      "[18/55] Processing node 21: Richard Langley, Stephen F. Austin State University\n",
      "Content length: 649 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 227 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 4 items\n",
      "\n",
      "[19/55] Processing node 23: Contributing authors\n",
      "Content length: 583 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 118 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 1 items\n",
      "\n",
      "[20/55] Processing node 24: Reviewers\n",
      "Content length: 2280 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 85 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 2 items\n",
      "  ✓ Sentences: 1 items\n",
      "\n",
      "[21/55] Processing node 25: Chapter 1 - Essential Ideas\n",
      "Content length: 1971 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 141 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 6 items\n",
      "  ✓ Sentences: 13 items\n",
      "\n",
      "[22/55] Processing node 26: 1.1 Chemistry in Context\n",
      "Content length: 2726 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 237 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 5 items\n",
      "  ✓ Sentences: 19 items\n",
      "\n",
      "[23/55] Processing node 27: Chemistry: The Central Science\n",
      "Content length: 2763 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 203 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 3 items\n",
      "  ✓ Sentences: 17 items\n",
      "\n",
      "[24/55] Processing node 28: The Scientific Method\n",
      "Content length: 1900 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 176 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 3 items\n",
      "  ✓ Sentences: 14 items\n",
      "\n",
      "[25/55] Processing node 29: The Domains of Chemistry\n",
      "Content length: 3742 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 163 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 7 items\n",
      "  ✓ Sentences: 27 items\n",
      "\n",
      "[26/55] Processing node 30: 1.2 Phases and Classification of Matter\n",
      "Content length: 5955 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 249 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 16 items\n",
      "  ✓ Sentences: 44 items\n",
      "\n",
      "[27/55] Processing node 31: Classifying Matter\n",
      "Content length: 6699 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 254 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 20 items\n",
      "  ✓ Sentences: 47 items\n",
      "\n",
      "[28/55] Processing node 32: Atoms and Molecules\n",
      "Content length: 5066 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 148 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 8 items\n",
      "  ✓ Sentences: 37 items\n",
      "\n",
      "[29/55] Processing node 33: 1.2 Phases and Classification of Matter Chemistry in Everyday Life\n",
      "Content length: 2214 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 203 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 6 items\n",
      "  ✓ Sentences: 19 items\n",
      "\n",
      "[30/55] Processing node 34: 1.2 Phases and Classification of Matter Chemistry in Everyday Life\n",
      "Content length: 1428 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 186 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 3 items\n",
      "  ✓ Sentences: 9 items\n",
      "\n",
      "[31/55] Processing node 35: 1.3 Physical and Chemical Properties\n",
      "Content length: 5010 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 182 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 9 items\n",
      "  ✓ Sentences: 34 items\n",
      "\n",
      "[32/55] Processing node 36: 1.3 Physical and Chemical Properties Chemistry in Everyday Life\n",
      "Content length: 4235 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 182 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 9 items\n",
      "  ✓ Sentences: 17 items\n",
      "\n",
      "[33/55] Processing node 37: 1.4 Measurements\n",
      "Content length: 5170 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 214 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 14 items\n",
      "  ✓ Sentences: 25 items\n",
      "\n",
      "[34/55] Processing node 38: SI Base Units\n",
      "Content length: 393 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 162 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 4 items\n",
      "\n",
      "[35/55] Processing node 39: Length\n",
      "Content length: 929 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 148 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 2 items\n",
      "  ✓ Sentences: 7 items\n",
      "\n",
      "[36/55] Processing node 40: Mass\n",
      "Content length: 761 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 189 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 2 items\n",
      "  ✓ Sentences: 8 items\n",
      "\n",
      "[37/55] Processing node 41: Temperature\n",
      "Content length: 920 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 143 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 2 items\n",
      "  ✓ Sentences: 7 items\n",
      "\n",
      "[38/55] Processing node 42: Time\n",
      "Content length: 314 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 133 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 3 items\n",
      "\n",
      "[39/55] Processing node 43: Derived SI Units\n",
      "Content length: 197 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 113 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 2 items\n",
      "\n",
      "[40/55] Processing node 44: Volume\n",
      "Content length: 1389 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 184 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 4 items\n",
      "  ✓ Sentences: 14 items\n",
      "\n",
      "[41/55] Processing node 45: Density\n",
      "Content length: 2471 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 128 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 7 items\n",
      "  ✓ Sentences: 11 items\n",
      "\n",
      "[42/55] Processing node 46: Example 1.1\n",
      "Content length: 1776 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 155 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 11 items\n",
      "  ✓ Sentences: 10 items\n",
      "\n",
      "[43/55] Processing node 47: Example 1.2\n",
      "Content length: 1731 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 183 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 12 items\n",
      "  ✓ Sentences: 11 items\n",
      "\n",
      "[44/55] Processing node 48: 1.5 Measurement Uncertainty, Accuracy, and Precision\n",
      "Content length: 925 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 185 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 3 items\n",
      "  ✓ Sentences: 6 items\n",
      "\n",
      "[45/55] Processing node 49: Significant Figures in Measurement\n",
      "Content length: 5523 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 188 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 9 items\n",
      "  ✓ Sentences: 39 items\n",
      "\n",
      "[46/55] Processing node 50: Significant Figures in Calculations\n",
      "Content length: 1935 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 190 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 6 items\n",
      "  ✓ Sentences: 8 items\n",
      "\n",
      "[47/55] Processing node 51: Example 1.3\n",
      "Content length: 937 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 168 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 7 items\n",
      "  ✓ Sentences: 1 items\n",
      "\n",
      "[48/55] Processing node 52: Example 1.4\n",
      "Content length: 756 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 144 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 10 items\n",
      "  ✓ Sentences: 7 items\n",
      "\n",
      "[49/55] Processing node 53: Example 1.5\n",
      "Content length: 1440 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 144 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 14 items\n",
      "  ✓ Sentences: 6 items\n",
      "\n",
      "[50/55] Processing node 54: Example 1.6\n",
      "Content length: 694 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 132 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 6 items\n",
      "  ✓ Sentences: 4 items\n",
      "\n",
      "[51/55] Processing node 55: Example 1.7\n",
      "Content length: 1619 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 203 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 15 items\n",
      "  ✓ Sentences: 10 items\n",
      "\n",
      "[52/55] Processing node 56: Accuracy and Precision\n",
      "Content length: 2263 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 190 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 6 items\n",
      "  ✓ Sentences: 13 items\n",
      "\n",
      "[53/55] Processing node 57: 1.6 Mathematical Treatment of Measurement Results\n",
      "Content length: 2790 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 152 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 12 items\n",
      "  ✓ Sentences: 10 items\n",
      "\n",
      "[54/55] Processing node 58: Conversion Factors and Dimensional Analysis\n",
      "Content length: 2153 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 187 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 8 items\n",
      "  ✓ Sentences: 16 items\n",
      "\n",
      "[55/55] Processing node 59: Example 1.8\n",
      "Content length: 928 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 124 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 9 items\n",
      "  ✓ Sentences: 5 items\n",
      "\n",
      "================================================================================\n",
      "CONTENT PROCESSING COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Creating inverse index using InverseIndexBuilder...\n",
      "Building n-gram indexes...\n",
      "Index stats: 2506 monograms, 6559 bigrams, 7235 trigrams\n",
      "✓ N-gram inverse indexes created successfully!\n",
      "    - Monograms: 2506 terms\n",
      "    - Bigrams: 6559 terms\n",
      "    - Trigrams: 7235 terms\n",
      "✓ Average nodes per term: 1.92\n",
      "✓ Most common monogram terms:\n",
      "    'chemistry': 20 nodes\n",
      "    'image': 20 nodes\n",
      "    'learning': 18 nodes\n",
      "    'used': 18 nodes\n",
      "    'one': 18 nodes\n",
      "    'example': 17 nodes\n",
      "    'figure': 17 nodes\n",
      "    'may': 16 nodes\n",
      "    'use': 15 nodes\n",
      "    'mass': 15 nodes\n",
      "\n",
      "================================================================================\n",
      "TREE CONTENT PROCESSING FINISHED!\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING SEARCH METHODS\n",
      "================================================================================\n",
      "\n",
      "==================================================\n",
      "Testing query: 'chemistry atoms'\n",
      "==================================================\n",
      "\n",
      "1. search_content(use_ngrams=True):\n",
      "   Found 3 results:\n",
      "     1. [29] The Domains of Chemistry (score: 0.667)\n",
      "     2. [32] Atoms and Molecules (score: 0.667)\n",
      "     3. [2] Preface (score: 0.333)\n",
      "\n",
      "2. search_content(use_ngrams=False):\n",
      "   Found 3 results:\n",
      "     1. [29] The Domains of Chemistry (score: 2)\n",
      "     2. [32] Atoms and Molecules (score: 2)\n",
      "     3. [2] Preface (score: 1)\n",
      "\n",
      "3. enhanced_search():\n",
      "   Found 3 results:\n",
      "     1. [29] The Domains of Chemistry (score: 0.267)\n",
      "     2. [32] Atoms and Molecules (score: 0.267)\n",
      "     3. [2] Preface (score: 0.133)\n",
      "\n",
      "4. search_content_tree():\n",
      "   Found 3 nodes:\n",
      "     1. [29] The Domains of Chemistry\n",
      "     2. [32] Atoms and Molecules\n",
      "     3. [2] Preface\n",
      "\n",
      "5. search_inverse_index() [DEPRECATED]:\n",
      "Warning: search_inverse_index() is deprecated. Use search_content() instead.\n",
      "   Found 3 results:\n",
      "     1. [29] The Domains of Chemistry (score: 2)\n",
      "     2. [32] Atoms and Molecules (score: 2)\n",
      "     3. [2] Preface (score: 1)\n",
      "\n",
      "==================================================\n",
      "Testing query: 'measurements accuracy'\n",
      "==================================================\n",
      "\n",
      "1. search_content(use_ngrams=True):\n",
      "   Found 3 results:\n",
      "     1. [48] 1.5 Measurement Uncertainty, Accuracy, and Precision (score: 0.667)\n",
      "     2. [56] Accuracy and Precision (score: 0.667)\n",
      "     3. [25] Chapter 1 - Essential Ideas (score: 0.667)\n",
      "\n",
      "2. search_content(use_ngrams=False):\n",
      "   Found 3 results:\n",
      "     1. [25] Chapter 1 - Essential Ideas (score: 2)\n",
      "     2. [48] 1.5 Measurement Uncertainty, Accuracy, and Precision (score: 2)\n",
      "     3. [56] Accuracy and Precision (score: 2)\n",
      "\n",
      "3. enhanced_search():\n",
      "   Found 3 results:\n",
      "     1. [48] 1.5 Measurement Uncertainty, Accuracy, and Precision (score: 0.267)\n",
      "     2. [56] Accuracy and Precision (score: 0.267)\n",
      "     3. [25] Chapter 1 - Essential Ideas (score: 0.267)\n",
      "\n",
      "4. search_content_tree():\n",
      "   Found 3 nodes:\n",
      "     1. [48] 1.5 Measurement Uncertainty, Accuracy, and Precision\n",
      "     2. [56] Accuracy and Precision\n",
      "     3. [25] Chapter 1 - Essential Ideas\n",
      "\n",
      "5. search_inverse_index() [DEPRECATED]:\n",
      "Warning: search_inverse_index() is deprecated. Use search_content() instead.\n",
      "   Found 3 results:\n",
      "     1. [25] Chapter 1 - Essential Ideas (score: 2)\n",
      "     2. [48] 1.5 Measurement Uncertainty, Accuracy, and Precision (score: 2)\n",
      "     3. [56] Accuracy and Precision (score: 2)\n",
      "\n",
      "==================================================\n",
      "Testing query: 'density volume'\n",
      "==================================================\n",
      "\n",
      "1. search_content(use_ngrams=True):\n",
      "   Found 3 results:\n",
      "     1. [35] 1.3 Physical and Chemical Properties (score: 0.667)\n",
      "     2. [37] 1.4 Measurements (score: 0.667)\n",
      "     3. [43] Derived SI Units (score: 0.667)\n",
      "\n",
      "2. search_content(use_ngrams=False):\n",
      "   Found 3 results:\n",
      "     1. [35] 1.3 Physical and Chemical Properties (score: 2)\n",
      "     2. [37] 1.4 Measurements (score: 2)\n",
      "     3. [43] Derived SI Units (score: 2)\n",
      "\n",
      "3. enhanced_search():\n",
      "   Found 3 results:\n",
      "     1. [35] 1.3 Physical and Chemical Properties (score: 0.267)\n",
      "     2. [37] 1.4 Measurements (score: 0.267)\n",
      "     3. [43] Derived SI Units (score: 0.267)\n",
      "\n",
      "4. search_content_tree():\n",
      "   Found 3 nodes:\n",
      "     1. [35] 1.3 Physical and Chemical Properties\n",
      "     2. [37] 1.4 Measurements\n",
      "     3. [43] Derived SI Units\n",
      "\n",
      "5. search_inverse_index() [DEPRECATED]:\n",
      "Warning: search_inverse_index() is deprecated. Use search_content() instead.\n",
      "   Found 3 results:\n",
      "     1. [35] 1.3 Physical and Chemical Properties (score: 2)\n",
      "     2. [37] 1.4 Measurements (score: 2)\n",
      "     3. [43] Derived SI Units (score: 2)\n",
      "\n",
      "==================================================\n",
      "Testing query: 'scientific method'\n",
      "==================================================\n",
      "\n",
      "1. search_content(use_ngrams=True):\n",
      "   Found 3 results:\n",
      "     1. [26] 1.1 Chemistry in Context (score: 1.333)\n",
      "     2. [28] The Scientific Method (score: 1.333)\n",
      "     3. [37] 1.4 Measurements (score: 0.333)\n",
      "\n",
      "2. search_content(use_ngrams=False):\n",
      "   Found 3 results:\n",
      "     1. [26] 1.1 Chemistry in Context (score: 2)\n",
      "     2. [28] The Scientific Method (score: 2)\n",
      "     3. [9] Changes to the second edition (score: 1)\n",
      "\n",
      "3. enhanced_search():\n",
      "   Found 3 results:\n",
      "     1. [26] 1.1 Chemistry in Context (score: 0.533)\n",
      "     2. [28] The Scientific Method (score: 0.533)\n",
      "     3. [37] 1.4 Measurements (score: 0.133)\n",
      "\n",
      "4. search_content_tree():\n",
      "   Found 3 nodes:\n",
      "     1. [26] 1.1 Chemistry in Context\n",
      "     2. [28] The Scientific Method\n",
      "     3. [37] 1.4 Measurements\n",
      "\n",
      "5. search_inverse_index() [DEPRECATED]:\n",
      "Warning: search_inverse_index() is deprecated. Use search_content() instead.\n",
      "   Found 3 results:\n",
      "     1. [26] 1.1 Chemistry in Context (score: 2)\n",
      "     2. [28] The Scientific Method (score: 2)\n",
      "     3. [9] Changes to the second edition (score: 1)\n",
      "\n",
      "================================================================================\n",
      "TESTING SEARCH INDEX AVAILABILITY\n",
      "================================================================================\n",
      "Has inverse_index_builder: True\n",
      "Has basic inverse_index: True\n",
      "N-gram indexes available:\n",
      "  - Monograms: 2506 terms\n",
      "  - Bigrams: 6559 terms\n",
      "  - Trigrams: 7235 terms\n",
      "\n",
      "================================================================================\n",
      "✅ UNIFIED SEARCH TESTING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "🎉 All search methods tested successfully!\n"
     ]
    }
   ],
   "source": [
    "from content_tree import ContentTree\n",
    "\n",
    "def test_unified_search():\n",
    "    \"\"\"Test the unified search methods.\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"TESTING UNIFIED SEARCH FUNCTIONALITY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create a ContentTree instance\n",
    "    tree = ContentTree()\n",
    "    \n",
    "    # Build the textbook tree from markdown files (limited to 2 files for testing)\n",
    "    md_directory = \"/Users/chemxai/GenAI/AI_Tutor/mcp_kb/md_files\"\n",
    "    print(f\"Building tree from: {md_directory}\")\n",
    "    tree.build_textbook_tree(md_directory)\n",
    "    \n",
    "    # Rename repeating headers to make them unique\n",
    "    tree.rename_repeating_headers()\n",
    "    \n",
    "    # Process content to create search indexes\n",
    "    print(\"\\nProcessing content and creating search indexes...\")\n",
    "    tree.process_tree_content(\n",
    "        max_summary_words=20,\n",
    "        max_keywords=5,\n",
    "        generate_embeddings=False,  # Disabled for faster testing\n",
    "        create_inverse_index=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TESTING SEARCH METHODS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    test_queries = [\n",
    "        \"chemistry atoms\",\n",
    "        \"measurements accuracy\",\n",
    "        \"density volume\",\n",
    "        \"scientific method\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Testing query: '{query}'\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Test main search_content method with n-grams\n",
    "        print(\"\\n1. search_content(use_ngrams=True):\")\n",
    "        try:\n",
    "            results_ngrams = tree.search_content(query, max_results=3, use_ngrams=True)\n",
    "            print(f\"   Found {len(results_ngrams)} results:\")\n",
    "            for i, (node_id, score) in enumerate(results_ngrams, 1):\n",
    "                node = next((n for n in tree.tree_node_iterator() if n.node_id == node_id), None)\n",
    "                if node:\n",
    "                    print(f\"     {i}. [{node_id}] {node.header} (score: {score:.3f})\")\n",
    "                else:\n",
    "                    print(f\"     {i}. [Node {node_id} not found] (score: {score:.3f})\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error: {e}\")\n",
    "        \n",
    "        # Test main search_content method without n-grams\n",
    "        print(\"\\n2. search_content(use_ngrams=False):\")\n",
    "        try:\n",
    "            results_simple = tree.search_content(query, max_results=3, use_ngrams=False)\n",
    "            print(f\"   Found {len(results_simple)} results:\")\n",
    "            for i, (node_id, score) in enumerate(results_simple, 1):\n",
    "                node = next((n for n in tree.tree_node_iterator() if n.node_id == node_id), None)\n",
    "                if node:\n",
    "                    print(f\"     {i}. [{node_id}] {node.header} (score: {score})\")\n",
    "                else:\n",
    "                    print(f\"     {i}. [Node {node_id} not found] (score: {score})\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error: {e}\")\n",
    "        \n",
    "        # Test enhanced search\n",
    "        print(\"\\n3. enhanced_search():\")\n",
    "        try:\n",
    "            enhanced_results = tree.enhanced_search(query, max_results=3)\n",
    "            print(f\"   Found {len(enhanced_results)} results:\")\n",
    "            for i, (node_id, score) in enumerate(enhanced_results, 1):\n",
    "                node = next((n for n in tree.tree_node_iterator() if n.node_id == node_id), None)\n",
    "                if node:\n",
    "                    print(f\"     {i}. [{node_id}] {node.header} (score: {score:.3f})\")\n",
    "                else:\n",
    "                    print(f\"     {i}. [Node {node_id} not found] (score: {score:.3f})\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error: {e}\")\n",
    "        \n",
    "        # Test search_content_tree (returns actual nodes)\n",
    "        print(\"\\n4. search_content_tree():\")\n",
    "        try:\n",
    "            node_results = tree.search_content_tree(query, max_results=3, use_ngrams=True)\n",
    "            print(f\"   Found {len(node_results)} nodes:\")\n",
    "            for i, node in enumerate(node_results, 1):\n",
    "                print(f\"     {i}. [{node.node_id}] {node.header}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error: {e}\")\n",
    "        \n",
    "        # Test deprecated method (should show warning)\n",
    "        print(\"\\n5. search_inverse_index() [DEPRECATED]:\")\n",
    "        try:\n",
    "            deprecated_results = tree.search_inverse_index(query, max_results=3)\n",
    "            print(f\"   Found {len(deprecated_results)} results:\")\n",
    "            for i, (node_id, score) in enumerate(deprecated_results, 1):\n",
    "                node = next((n for n in tree.tree_node_iterator() if n.node_id == node_id), None)\n",
    "                if node:\n",
    "                    print(f\"     {i}. [{node_id}] {node.header} (score: {score})\")\n",
    "                else:\n",
    "                    print(f\"     {i}. [Node {node_id} not found] (score: {score})\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TESTING SEARCH INDEX AVAILABILITY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Test search indexes\n",
    "    print(f\"Has inverse_index_builder: {hasattr(tree, 'inverse_index_builder') and tree.inverse_index_builder is not None}\")\n",
    "    print(f\"Has basic inverse_index: {hasattr(tree, 'inverse_index') and len(tree.inverse_index) > 0}\")\n",
    "    \n",
    "    if hasattr(tree, 'inverse_index_builder') and tree.inverse_index_builder:\n",
    "        print(f\"N-gram indexes available:\")\n",
    "        print(f\"  - Monograms: {len(tree.inverse_index_builder.monogram_index)} terms\")\n",
    "        print(f\"  - Bigrams: {len(tree.inverse_index_builder.bigram_index)} terms\")\n",
    "        print(f\"  - Trigrams: {len(tree.inverse_index_builder.trigram_index)} terms\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✅ UNIFIED SEARCH TESTING COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    success = test_unified_search()\n",
    "    if success:\n",
    "        print(\"\\n🎉 All search methods tested successfully!\")\n",
    "    else:\n",
    "        print(\"\\n❌ Some tests failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0633c62-1449-434d-9f01-912f0e2cc477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TESTING NORMALIZED N-GRAM SCORING\n",
      "================================================================================\n",
      "Building tree from: /Users/chemxai/GenAI/AI_Tutor/mcp_kb/md_files\n",
      "\n",
      "Processing content and creating search indexes...\n",
      "================================================================================\n",
      "COMPREHENSIVE CONTENT TREE PROCESSING\n",
      "================================================================================\n",
      "Processing 55 content nodes...\n",
      "LLM Model: qwen2.5vl:32b\n",
      "Embedding Model: text-embedding-3-large\n",
      "Generate Embeddings: False\n",
      "Create Inverse Index: True\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/55] Processing node 2: Preface\n",
      "Content length: 205 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 106 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 2 items\n",
      "\n",
      "[2/55] Processing node 3: About OpenStax\n",
      "Content length: 668 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 151 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 4 items\n",
      "\n",
      "[3/55] Processing node 4: About OpenStax resources Customization\n",
      "Content length: 944 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 204 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 3 items\n",
      "  ✓ Sentences: 7 items\n",
      "\n",
      "[4/55] Processing node 5: Errata\n",
      "Content length: 535 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 195 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 6 items\n",
      "\n",
      "[5/55] Processing node 6: Format\n",
      "Content length: 107 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 102 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 1 items\n",
      "\n",
      "[6/55] Processing node 7: About Chemistry 2e\n",
      "Content length: 744 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 191 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 5 items\n",
      "\n",
      "[7/55] Processing node 8: Coverage and scope\n",
      "Content length: 732 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 192 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 2 items\n",
      "  ✓ Sentences: 5 items\n",
      "\n",
      "[8/55] Processing node 9: Changes to the second edition\n",
      "Content length: 1681 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 171 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 4 items\n",
      "  ✓ Sentences: 15 items\n",
      "\n",
      "[9/55] Processing node 10: Pedagogical foundation and features\n",
      "Content length: 931 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 152 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 4 items\n",
      "  ✓ Sentences: 7 items\n",
      "\n",
      "[10/55] Processing node 11: Comprehensive art program\n",
      "Content length: 253 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 115 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 4 items\n",
      "  ✓ Sentences: 4 items\n",
      "\n",
      "[11/55] Processing node 12: Interactives that engage\n",
      "Content length: 226 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 151 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 2 items\n",
      "  ✓ Sentences: 2 items\n",
      "\n",
      "[12/55] Processing node 13: Assessments that reinforce key concepts\n",
      "Content length: 316 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 170 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 2 items\n",
      "\n",
      "[13/55] Processing node 15: Student and instructor resources\n",
      "Content length: 367 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 149 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 3 items\n",
      "\n",
      "[14/55] Processing node 16: Community Hubs\n",
      "Content length: 757 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 159 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 4 items\n",
      "\n",
      "[15/55] Processing node 17: Technology partners\n",
      "Content length: 244 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 131 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 2 items\n",
      "\n",
      "[16/55] Processing node 19: Paul Flowers, University of North Carolina at Pembroke\n",
      "Content length: 503 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 186 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 3 items\n",
      "\n",
      "[17/55] Processing node 20: Klaus Theopold, University of Delaware\n",
      "Content length: 682 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 192 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 5 items\n",
      "\n",
      "[18/55] Processing node 21: Richard Langley, Stephen F. Austin State University\n",
      "Content length: 649 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 227 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 4 items\n",
      "\n",
      "[19/55] Processing node 23: Contributing authors\n",
      "Content length: 583 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 118 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 1 items\n",
      "\n",
      "[20/55] Processing node 24: Reviewers\n",
      "Content length: 2280 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 85 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 2 items\n",
      "  ✓ Sentences: 1 items\n",
      "\n",
      "[21/55] Processing node 25: Chapter 1 - Essential Ideas\n",
      "Content length: 1971 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 141 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 6 items\n",
      "  ✓ Sentences: 13 items\n",
      "\n",
      "[22/55] Processing node 26: 1.1 Chemistry in Context\n",
      "Content length: 2726 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 237 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 5 items\n",
      "  ✓ Sentences: 19 items\n",
      "\n",
      "[23/55] Processing node 27: Chemistry: The Central Science\n",
      "Content length: 2763 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 203 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 3 items\n",
      "  ✓ Sentences: 17 items\n",
      "\n",
      "[24/55] Processing node 28: The Scientific Method\n",
      "Content length: 1900 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 176 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 3 items\n",
      "  ✓ Sentences: 14 items\n",
      "\n",
      "[25/55] Processing node 29: The Domains of Chemistry\n",
      "Content length: 3742 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 163 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 7 items\n",
      "  ✓ Sentences: 27 items\n",
      "\n",
      "[26/55] Processing node 30: 1.2 Phases and Classification of Matter\n",
      "Content length: 5955 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 249 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 16 items\n",
      "  ✓ Sentences: 44 items\n",
      "\n",
      "[27/55] Processing node 31: Classifying Matter\n",
      "Content length: 6699 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 254 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 20 items\n",
      "  ✓ Sentences: 47 items\n",
      "\n",
      "[28/55] Processing node 32: Atoms and Molecules\n",
      "Content length: 5066 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 148 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 8 items\n",
      "  ✓ Sentences: 37 items\n",
      "\n",
      "[29/55] Processing node 33: 1.2 Phases and Classification of Matter Chemistry in Everyday Life\n",
      "Content length: 2214 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 203 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 6 items\n",
      "  ✓ Sentences: 19 items\n",
      "\n",
      "[30/55] Processing node 34: 1.2 Phases and Classification of Matter Chemistry in Everyday Life\n",
      "Content length: 1428 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 186 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 3 items\n",
      "  ✓ Sentences: 9 items\n",
      "\n",
      "[31/55] Processing node 35: 1.3 Physical and Chemical Properties\n",
      "Content length: 5010 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 182 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 9 items\n",
      "  ✓ Sentences: 34 items\n",
      "\n",
      "[32/55] Processing node 36: 1.3 Physical and Chemical Properties Chemistry in Everyday Life\n",
      "Content length: 4235 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 182 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 9 items\n",
      "  ✓ Sentences: 17 items\n",
      "\n",
      "[33/55] Processing node 37: 1.4 Measurements\n",
      "Content length: 5170 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 214 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 14 items\n",
      "  ✓ Sentences: 25 items\n",
      "\n",
      "[34/55] Processing node 38: SI Base Units\n",
      "Content length: 393 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 162 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 4 items\n",
      "\n",
      "[35/55] Processing node 39: Length\n",
      "Content length: 929 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 148 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 2 items\n",
      "  ✓ Sentences: 7 items\n",
      "\n",
      "[36/55] Processing node 40: Mass\n",
      "Content length: 761 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 189 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 2 items\n",
      "  ✓ Sentences: 8 items\n",
      "\n",
      "[37/55] Processing node 41: Temperature\n",
      "Content length: 920 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 143 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 2 items\n",
      "  ✓ Sentences: 7 items\n",
      "\n",
      "[38/55] Processing node 42: Time\n",
      "Content length: 314 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 133 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 3 items\n",
      "\n",
      "[39/55] Processing node 43: Derived SI Units\n",
      "Content length: 197 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 113 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 1 items\n",
      "  ✓ Sentences: 2 items\n",
      "\n",
      "[40/55] Processing node 44: Volume\n",
      "Content length: 1389 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 184 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 4 items\n",
      "  ✓ Sentences: 14 items\n",
      "\n",
      "[41/55] Processing node 45: Density\n",
      "Content length: 2471 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 128 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 7 items\n",
      "  ✓ Sentences: 11 items\n",
      "\n",
      "[42/55] Processing node 46: Example 1.1\n",
      "Content length: 1776 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 155 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 11 items\n",
      "  ✓ Sentences: 10 items\n",
      "\n",
      "[43/55] Processing node 47: Example 1.2\n",
      "Content length: 1731 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 183 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 12 items\n",
      "  ✓ Sentences: 11 items\n",
      "\n",
      "[44/55] Processing node 48: 1.5 Measurement Uncertainty, Accuracy, and Precision\n",
      "Content length: 925 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 185 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 3 items\n",
      "  ✓ Sentences: 6 items\n",
      "\n",
      "[45/55] Processing node 49: Significant Figures in Measurement\n",
      "Content length: 5523 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 188 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 9 items\n",
      "  ✓ Sentences: 39 items\n",
      "\n",
      "[46/55] Processing node 50: Significant Figures in Calculations\n",
      "Content length: 1935 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 190 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 6 items\n",
      "  ✓ Sentences: 8 items\n",
      "\n",
      "[47/55] Processing node 51: Example 1.3\n",
      "Content length: 937 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 168 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 7 items\n",
      "  ✓ Sentences: 1 items\n",
      "\n",
      "[48/55] Processing node 52: Example 1.4\n",
      "Content length: 756 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 144 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 10 items\n",
      "  ✓ Sentences: 7 items\n",
      "\n",
      "[49/55] Processing node 53: Example 1.5\n",
      "Content length: 1440 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 144 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 14 items\n",
      "  ✓ Sentences: 6 items\n",
      "\n",
      "[50/55] Processing node 54: Example 1.6\n",
      "Content length: 694 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 132 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 6 items\n",
      "  ✓ Sentences: 4 items\n",
      "\n",
      "[51/55] Processing node 55: Example 1.7\n",
      "Content length: 1619 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 203 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 15 items\n",
      "  ✓ Sentences: 10 items\n",
      "\n",
      "[52/55] Processing node 56: Accuracy and Precision\n",
      "Content length: 2263 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 190 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 6 items\n",
      "  ✓ Sentences: 13 items\n",
      "\n",
      "[53/55] Processing node 57: 1.6 Mathematical Treatment of Measurement Results\n",
      "Content length: 2790 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 152 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 12 items\n",
      "  ✓ Sentences: 10 items\n",
      "\n",
      "[54/55] Processing node 58: Conversion Factors and Dimensional Analysis\n",
      "Content length: 2153 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 187 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 8 items\n",
      "  ✓ Sentences: 16 items\n",
      "\n",
      "[55/55] Processing node 59: Example 1.8\n",
      "Content length: 928 characters\n",
      "Process node content ........\n",
      "Generating summary...\n",
      "Generating keywords...\n",
      "  ✓ Summary: 124 chars\n",
      "  ✓ Keywords: 4 items\n",
      "  ✓ Chunks: 9 items\n",
      "  ✓ Sentences: 5 items\n",
      "\n",
      "================================================================================\n",
      "CONTENT PROCESSING COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Creating inverse index using InverseIndexBuilder...\n",
      "Building n-gram indexes...\n",
      "Index stats: 2506 monograms, 6559 bigrams, 7235 trigrams\n",
      "✓ N-gram inverse indexes created successfully!\n",
      "    - Monograms: 2506 terms\n",
      "    - Bigrams: 6559 terms\n",
      "    - Trigrams: 7235 terms\n",
      "✓ Average nodes per term: 1.92\n",
      "✓ Most common monogram terms:\n",
      "    'chemistry': 20 nodes\n",
      "    'image': 20 nodes\n",
      "    'learning': 18 nodes\n",
      "    'used': 18 nodes\n",
      "    'one': 18 nodes\n",
      "    'example': 17 nodes\n",
      "    'figure': 17 nodes\n",
      "    'may': 16 nodes\n",
      "    'use': 15 nodes\n",
      "    'mass': 15 nodes\n",
      "\n",
      "================================================================================\n",
      "TREE CONTENT PROCESSING FINISHED!\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TESTING SCORE NORMALIZATION\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "Testing query: 'chemistry'\n",
      "Query length: 1 words\n",
      "============================================================\n",
      "\n",
      "RAW SCORES (unbounded):\n",
      "  Max raw score: 1.000\n",
      "    1. [2] Preface (score: 1.000)\n",
      "    2. [4] About OpenStax resources Customization (score: 1.000)\n",
      "    3. [7] About Chemistry 2e (score: 1.000)\n",
      "\n",
      "NORMALIZED SCORES (0-1.0 range):\n",
      "  Max normalized score: 1.000\n",
      "    1. [2] Preface (score: 1.000)\n",
      "    2. [4] About OpenStax resources Customization (score: 1.000)\n",
      "    3. [7] About Chemistry 2e (score: 1.000)\n",
      "\n",
      "Max possible score for this query: 1.000\n",
      "Normalization factor: 1.000\n",
      "\n",
      "============================================================\n",
      "Testing query: 'chemistry atoms'\n",
      "Query length: 2 words\n",
      "============================================================\n",
      "\n",
      "RAW SCORES (unbounded):\n",
      "  Max raw score: 0.667\n",
      "    1. [29] The Domains of Chemistry (score: 0.667)\n",
      "    2. [32] Atoms and Molecules (score: 0.667)\n",
      "    3. [2] Preface (score: 0.333)\n",
      "\n",
      "NORMALIZED SCORES (0-1.0 range):\n",
      "  Max normalized score: 0.333\n",
      "    1. [29] The Domains of Chemistry (score: 0.333)\n",
      "    2. [32] Atoms and Molecules (score: 0.333)\n",
      "    3. [2] Preface (score: 0.167)\n",
      "\n",
      "Max possible score for this query: 2.000\n",
      "Normalization factor: 0.333\n",
      "\n",
      "============================================================\n",
      "Testing query: 'chemistry atoms molecules structure bonds'\n",
      "Query length: 5 words\n",
      "============================================================\n",
      "\n",
      "RAW SCORES (unbounded):\n",
      "  Max raw score: 0.667\n",
      "    1. [32] Atoms and Molecules (score: 0.667)\n",
      "    2. [30] 1.2 Phases and Classification of Matter (score: 0.500)\n",
      "    3. [29] The Domains of Chemistry (score: 0.333)\n",
      "\n",
      "NORMALIZED SCORES (0-1.0 range):\n",
      "  Max normalized score: 0.167\n",
      "    1. [32] Atoms and Molecules (score: 0.167)\n",
      "    2. [30] 1.2 Phases and Classification of Matter (score: 0.125)\n",
      "    3. [29] The Domains of Chemistry (score: 0.083)\n",
      "\n",
      "Max possible score for this query: 4.000\n",
      "Normalization factor: 0.167\n",
      "\n",
      "============================================================\n",
      "Testing query: 'measurements accuracy precision uncertainty'\n",
      "Query length: 4 words\n",
      "============================================================\n",
      "\n",
      "RAW SCORES (unbounded):\n",
      "  Max raw score: 0.889\n",
      "    1. [48] 1.5 Measurement Uncertainty, Accuracy, and Precision (score: 0.889)\n",
      "    2. [25] Chapter 1 - Essential Ideas (score: 0.889)\n",
      "    3. [56] Accuracy and Precision (score: 0.778)\n",
      "\n",
      "NORMALIZED SCORES (0-1.0 range):\n",
      "  Max normalized score: 0.235\n",
      "    1. [48] 1.5 Measurement Uncertainty, Accuracy, and Precision (score: 0.235)\n",
      "    2. [25] Chapter 1 - Essential Ideas (score: 0.235)\n",
      "    3. [56] Accuracy and Precision (score: 0.206)\n",
      "\n",
      "Max possible score for this query: 3.778\n",
      "Normalization factor: 0.235\n",
      "\n",
      "============================================================\n",
      "Testing query: 'scientific method observation hypothesis'\n",
      "Query length: 4 words\n",
      "============================================================\n",
      "\n",
      "RAW SCORES (unbounded):\n",
      "  Max raw score: 0.889\n",
      "    1. [28] The Scientific Method (score: 0.889)\n",
      "    2. [26] 1.1 Chemistry in Context (score: 0.667)\n",
      "    3. [32] Atoms and Molecules (score: 0.111)\n",
      "\n",
      "NORMALIZED SCORES (0-1.0 range):\n",
      "  Max normalized score: 0.235\n",
      "    1. [28] The Scientific Method (score: 0.235)\n",
      "    2. [26] 1.1 Chemistry in Context (score: 0.176)\n",
      "    3. [32] Atoms and Molecules (score: 0.029)\n",
      "\n",
      "Max possible score for this query: 3.778\n",
      "Normalization factor: 0.235\n",
      "\n",
      "================================================================================\n",
      "TESTING ENHANCED SEARCH WITH NORMALIZED SCORES\n",
      "================================================================================\n",
      "\n",
      "Testing enhanced_search with query: 'chemistry atoms molecules'\n",
      "\n",
      "Enhanced search results (using normalized lexical scores):\n",
      "  1. [32] Atoms and Molecules (combined score: 0.140)\n",
      "  2. [30] 1.2 Phases and Classification of Matter (combined score: 0.120)\n",
      "  3. [29] The Domains of Chemistry (combined score: 0.060)\n",
      "  4. [33] 1.2 Phases and Classification of Matter Chemistry in Everyday Life (combined score: 0.040)\n",
      "  5. [2] Preface (combined score: 0.020)\n",
      "\n",
      "================================================================================\n",
      "TESTING SEMANTIC + LEXICAL SCORE BALANCE\n",
      "================================================================================\n",
      "With normalized scores, semantic (0-1.0) and lexical (0-1.0) are now balanced!\n",
      "Example weights: semantic_weight=0.6, lexical_weight=0.4\n",
      "Max combined score would be: 0.6 * 1.0 + 0.4 * 1.0 = 1.0\n",
      "\n",
      "Example score combinations:\n",
      "  High semantic (0.9), High lexical (0.8): 0.860\n",
      "  Medium semantic (0.5), High lexical (0.9): 0.660\n",
      "  High semantic (0.8), Medium lexical (0.4): 0.640\n",
      "\n",
      "================================================================================\n",
      "✅ NORMALIZED SCORING TEST COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from content_tree import ContentTree\n",
    "\n",
    "def test_normalized_scoring():\n",
    "    \"\"\"Test the normalized scoring functionality.\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"TESTING NORMALIZED N-GRAM SCORING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create a ContentTree instance\n",
    "    tree = ContentTree()\n",
    "    \n",
    "    # Build the textbook tree from markdown files (limited to 2 files for testing)\n",
    "    md_directory = \"/Users/chemxai/GenAI/AI_Tutor/mcp_kb/md_files\"\n",
    "    print(f\"Building tree from: {md_directory}\")\n",
    "    tree.build_textbook_tree(md_directory)\n",
    "    \n",
    "    # Rename repeating headers to make them unique\n",
    "    tree.rename_repeating_headers()\n",
    "    \n",
    "    # Process content to create search indexes\n",
    "    print(\"\\nProcessing content and creating search indexes...\")\n",
    "    tree.process_tree_content(\n",
    "        max_summary_words=20,\n",
    "        max_keywords=5,\n",
    "        generate_embeddings=False,  # Disabled for faster testing\n",
    "        create_inverse_index=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TESTING SCORE NORMALIZATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    test_queries = [\n",
    "        \"chemistry\",\n",
    "        \"chemistry atoms\",\n",
    "        \"chemistry atoms molecules structure bonds\",\n",
    "        \"measurements accuracy precision uncertainty\",\n",
    "        \"scientific method observation hypothesis\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Testing query: '{query}'\")\n",
    "        print(f\"Query length: {len(query.split())} words\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Test with InverseIndexBuilder directly\n",
    "        if hasattr(tree, 'inverse_index_builder') and tree.inverse_index_builder:\n",
    "            builder = tree.inverse_index_builder\n",
    "            \n",
    "            # Calculate raw scores\n",
    "            raw_scores = builder.calculate_lexical_similarity(query)\n",
    "            \n",
    "            # Calculate normalized scores\n",
    "            normalized_scores = builder.calculate_normalized_lexical_similarity(query)\n",
    "            \n",
    "            # Get top 3 results for comparison\n",
    "            top_raw = sorted(raw_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "            top_normalized = sorted(normalized_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "            \n",
    "            print(\"\\nRAW SCORES (unbounded):\")\n",
    "            max_raw_score = max(raw_scores.values()) if raw_scores else 0\n",
    "            print(f\"  Max raw score: {max_raw_score:.3f}\")\n",
    "            for i, (node_id, score) in enumerate(top_raw, 1):\n",
    "                node = next((n for n in tree.tree_node_iterator() if n.node_id == node_id), None)\n",
    "                header = node.header if node else f\"Node {node_id}\"\n",
    "                print(f\"    {i}. [{node_id}] {header} (score: {score:.3f})\")\n",
    "            \n",
    "            print(\"\\nNORMALIZED SCORES (0-1.0 range):\")\n",
    "            max_normalized_score = max(normalized_scores.values()) if normalized_scores else 0\n",
    "            print(f\"  Max normalized score: {max_normalized_score:.3f}\")\n",
    "            for i, (node_id, score) in enumerate(top_normalized, 1):\n",
    "                node = next((n for n in tree.tree_node_iterator() if n.node_id == node_id), None)\n",
    "                header = node.header if node else f\"Node {node_id}\"\n",
    "                print(f\"    {i}. [{node_id}] {header} (score: {score:.3f})\")\n",
    "            \n",
    "            # Calculate maximum possible score for this query\n",
    "            query_tokens = builder._tokenize_and_clean(query)\n",
    "            query_monograms = query_tokens\n",
    "            query_bigrams = [f\"{query_tokens[i]} {query_tokens[i+1]}\" \n",
    "                            for i in range(len(query_tokens)-1)]\n",
    "            query_trigrams = [f\"{query_tokens[i]} {query_tokens[i+1]} {query_tokens[i+2]}\" \n",
    "                             for i in range(len(query_tokens)-2)]\n",
    "            \n",
    "            max_possible = builder._calculate_max_possible_score(query_monograms, query_bigrams, query_trigrams)\n",
    "            print(f\"\\nMax possible score for this query: {max_possible:.3f}\")\n",
    "            print(f\"Normalization factor: {max_raw_score/max_possible:.3f}\" if max_possible > 0 else \"N/A\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TESTING ENHANCED SEARCH WITH NORMALIZED SCORES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Test enhanced search which should now use normalized scores\n",
    "    test_query = \"chemistry atoms molecules\"\n",
    "    print(f\"\\nTesting enhanced_search with query: '{test_query}'\")\n",
    "    \n",
    "    enhanced_results = tree.enhanced_search(test_query, max_results=5)\n",
    "    print(f\"\\nEnhanced search results (using normalized lexical scores):\")\n",
    "    for i, (node_id, score) in enumerate(enhanced_results, 1):\n",
    "        node = next((n for n in tree.tree_node_iterator() if n.node_id == node_id), None)\n",
    "        header = node.header if node else f\"Node {node_id}\"\n",
    "        print(f\"  {i}. [{node_id}] {header} (combined score: {score:.3f})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TESTING SEMANTIC + LEXICAL SCORE BALANCE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Demonstrate the score balance issue and solution\n",
    "    print(\"With normalized scores, semantic (0-1.0) and lexical (0-1.0) are now balanced!\")\n",
    "    print(\"Example weights: semantic_weight=0.6, lexical_weight=0.4\")\n",
    "    print(\"Max combined score would be: 0.6 * 1.0 + 0.4 * 1.0 = 1.0\")\n",
    "    \n",
    "    # Show some example calculations\n",
    "    semantic_weight = 0.6\n",
    "    lexical_weight = 0.4\n",
    "    \n",
    "    print(f\"\\nExample score combinations:\")\n",
    "    print(f\"  High semantic (0.9), High lexical (0.8): {semantic_weight * 0.9 + lexical_weight * 0.8:.3f}\")\n",
    "    print(f\"  Medium semantic (0.5), High lexical (0.9): {semantic_weight * 0.5 + lexical_weight * 0.9:.3f}\")\n",
    "    print(f\"  High semantic (0.8), Medium lexical (0.4): {semantic_weight * 0.8 + lexical_weight * 0.4:.3f}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    success = test_normalized_scoring()\n",
    "    if success:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"✅ NORMALIZED SCORING TEST COMPLETE!\")\n",
    "        print(\"=\"*80)\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"❌ SOME TESTS FAILED!\")\n",
    "        print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32492b30-847c-4a81-a677-adc1f446a4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: torch in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.7.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from sentence-transformers) (0.33.1)\n",
      "Requirement already satisfied: Pillow in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/chemxai/miniforge3/envs/GenAI312/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.6.15)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Downloading scikit_learn-1.7.1-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m17.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:15\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn, sentence-transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.1 scikit-learn-1.7.1 sentence-transformers-5.0.0 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install -U sentence-transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827bbc00-3302-4490-ba6e-077cdf946034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
